{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“svm_rbf_multi”的副本",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PTzjDSjEX2Aggjdfa-IPLR8Wl6SMgiQO",
      "authorship_tag": "ABX9TyMSF6oRlQYFo5U9Gu7KQRyF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YintongMa/EEGDataMining/blob/main/svm_rbf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAAhPjLVY-s8"
      },
      "source": [
        "import numpy as np\n",
        "from functools import lru_cache\n",
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.utils import shuffle\n",
        "import os\n",
        "\n",
        "\n",
        "class svm():\n",
        "\n",
        "    def __init__(self,\n",
        "                 kernel=\"rbf\", lmd=1e-1, gamma=0.1, bias=1.0, max_iter=100):\n",
        "        if kernel not in self.__kernel_dict:\n",
        "            print(kernel + \" kernel does not exist!\\nUse rbf kernel.\")\n",
        "            kernel = \"rbf\"\n",
        "        if kernel == \"rbf\":\n",
        "            def kernel_func(x, y):\n",
        "                return self.__kernel_dict[kernel](x, y, gamma=gamma)\n",
        "        else:\n",
        "            kernel_func = self.__kernel_dict[kernel]\n",
        "        self.kernel = kernel_func\n",
        "        self.lmd = lmd\n",
        "        self.bias = bias\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def __linear_kernel(x, y):\n",
        "        return np.dot(x, y)\n",
        "\n",
        "    def __gaussian_kernel(x, y, gamma):\n",
        "        diff = x - y\n",
        "        return np.exp(-gamma * np.dot(diff, diff))\n",
        "\n",
        "    __kernel_dict = {\"linear\": __linear_kernel, \"rbf\": __gaussian_kernel}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        def update_alpha(alpha, t):\n",
        "            data_size, feature_size = np.shape(self.X_with_bias)\n",
        "            new_alpha = np.copy(alpha)\n",
        "            it = np.random.randint(low=0, high=data_size)\n",
        "            x_it = self.X_with_bias[it]\n",
        "            y_it = self.y[it]\n",
        "\n",
        "            # alpha[k] = alpha[k] + eta[k] * (1 - myData.loc[k, 2] * sum(alpha * myData.loc[:, 2] * K[:, k]))\n",
        "            if (y_it * (1. / (self.lmd * t)) * sum([alpha_j * y_it * self.kernel(x_it, x_j) for x_j, alpha_j in zip(self.X_with_bias, alpha)])) < 1.:\n",
        "                new_alpha[it] += 1\n",
        "            return new_alpha\n",
        "\n",
        "        self.X_with_bias = np.c_[X, np.ones((np.shape(X)[0])) * self.bias]\n",
        "        self.y = y\n",
        "        alpha = np.zeros((np.shape(self.X_with_bias)[0], 1))\n",
        "\n",
        "        for t in range(1, self.max_iter + 1):\n",
        "            alpha = update_alpha(alpha, t)\n",
        "        self.alpha = alpha\n",
        "        return alpha\n",
        "\n",
        "\n",
        "    def predict(self,X):\n",
        "        X_with_bias = np.c_[X, np.ones((np.shape(X)[0])) * self.bias]\n",
        "\n",
        "        y_score = []\n",
        "\n",
        "        for x in X_with_bias:\n",
        "            i = 0\n",
        "            for (x_j, y_j, alpha_j) in zip(self.X_with_bias, self.y, self.alpha):\n",
        "                i += alpha_j * y_j * self.kernel(x_j, x)\n",
        "            y_score.append((1. / (self.lmd * self.max_iter)) * i)\n",
        "\n",
        "        \n",
        "        return y_score\n",
        "\n",
        "\n",
        "def cross_val_binary(X, y, batch_size):\n",
        "    error_arr = []\n",
        "    subset_num = int(len(X)/batch_size)-1\n",
        "    for i in range(subset_num):\n",
        "        print('batch: '+str(i))\n",
        "        error = 0\n",
        "        X_test = X[i*batch_size: (i+1)*batch_size]\n",
        "        y_test = y[i*batch_size: (i+1)*batch_size]\n",
        "        X_train = np.concatenate((X[0: i*batch_size], X[(i+1)*batch_size: len(X)]))\n",
        "        y_train = np.concatenate((y[0: i*batch_size], y[(i+1)*batch_size: len(y)]))\n",
        "        \n",
        "        # Revised part, PCA fitting only applied to training set\n",
        "        pca = PCA()\n",
        "        X_train =  pca.fit_transform(X_train)\n",
        "        X_test = pca.transform(X_test)\n",
        "\n",
        "        print('training')\n",
        "        cf = svm(kernel=\"linear\")\n",
        "        cf.fit(X_train, y_train)\n",
        "\n",
        "        print('predicting')\n",
        "        y_score = cf.predict((X_test))\n",
        "        result = []\n",
        "        for s in y_score:\n",
        "            if s >= 0.:\n",
        "                result.append(1)\n",
        "            else:\n",
        "                result.append(-1)\n",
        "\n",
        "        for i in range(len(X_test)):\n",
        "            if result[i] != y_test[i]:\n",
        "                error = error + 1\n",
        "        error_rate = error/batch_size\n",
        "        error_arr.append(error_rate)\n",
        "    \n",
        "#     print (\"Error rate of each iteration: \" + str(error_arr))\n",
        "    print (\"Average error rate:\" + str(np.average(error_arr)))\n",
        "    print()\n",
        "    \n",
        "    return np.average(error_arr)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs2RRct6hNGW"
      },
      "source": [
        "# Binary tasks\n",
        "PATH = \"/content/drive/MyDrive/ML/data_binary\"\n",
        "file_list = os.listdir(PATH)\n",
        "file_list.sort()\n",
        "task = []\n",
        "result = []\n",
        "\n",
        "for file in file_list:\n",
        "    data = np.load(os.path.join(PATH, file))\n",
        "    X = data['x']\n",
        "    y = data['y']\n",
        "    print(file)\n",
        "    avg_err = cross_val_binary(X, y, int(len(X)/10))\n",
        "    task.append(file.split(\".\")[0])\n",
        "    result.append(avg_err)\n",
        "\n",
        "result_df = {\"task\": task,\"avg_err\": result}\n",
        "df = pd.DataFrame(result_df, columns = [\"task\",\"avg_err\"])\n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/ML/result/least_squares_binary.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lILPVARZH_1o"
      },
      "source": [
        "# Classify 10 different digit classes\n",
        "def cross_val_multi(X, y, batch_size):\n",
        "    error_arr = []\n",
        "    subset_num = int(len(X)/batch_size)-1\n",
        "    \n",
        "    for i in range(subset_num):\n",
        "        print(\"batch: \" + str(i))\n",
        "        error = 0\n",
        "        X_test = X[i * batch_size: (i + 1) * batch_size]\n",
        "        y_test = y[i * batch_size: (i + 1) * batch_size]\n",
        "        X_train = np.concatenate((X[0: i * batch_size], X[(i + 1) * batch_size: len(X)]))\n",
        "        label_train = np.concatenate((y[0: i * batch_size], y[(i + 1) * batch_size: len(y)]))\n",
        "        \n",
        "        \n",
        "        svm_list = []\n",
        "        for m in range(10):\n",
        "            print('building predictor for ' + str(m))\n",
        "            y_train = []\n",
        "            for j in range(len(label_train)):\n",
        "                if label_train[j] == i:\n",
        "                    y_train.append([1])\n",
        "                else:\n",
        "                    y_train.append([-1])\n",
        "            y_train = np.array(y_train)\n",
        "                    \n",
        "            pca = PCA()\n",
        "            X_train =  pca.fit_transform(X_train)\n",
        "            X_test = pca.transform(X_test)\n",
        "\n",
        "\n",
        "            cf = svm(kernel=\"rbf\")\n",
        "            cf.fit(X_train, y_train)\n",
        "            svm_list.append(cf)\n",
        "\n",
        "\n",
        "        print('predicting')\n",
        "        scores = np.zeros((len(svm_list),len(X_test)))\n",
        "        for i in range(len(svm_list)):\n",
        "            scores[i] = np.array(svm_list[i].predict((X_test))).flatten()\n",
        "\n",
        "        scores = scores.T\n",
        "        result = []\n",
        "        for j in range(len(y_test)):\n",
        "            result.append(np.abs(scores[j] - 1).argmin())\n",
        "            \n",
        "        for j in range(len(result)):\n",
        "            if result[j] != y_test[j]:\n",
        "                error = error + 1\n",
        "        \n",
        "        error_rate = error / batch_size\n",
        "        error_arr.append(error_rate)\n",
        "        print('error_rate: '+str(error_rate))\n",
        "        print('***************************')\n",
        "\n",
        "#     print(\"Error rate of each iteration: \" + str(error_arr))\n",
        "    print(\"Average error rate:\" + str(np.average(error_arr)))\n",
        "    return np.average(error_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlU3bJlrJx30",
        "outputId": "4d186fb3-961a-4018-de3f-d863de76f264"
      },
      "source": [
        "# Multiclass tasks\n",
        "task = \"classify 10 digit seeing\"\n",
        "data = np.load(\"/content/drive/MyDrive/ML/data_multi/all_raw_digit.npz\") \n",
        "x = data['x']\n",
        "y = data['y']\n",
        "\n",
        "\n",
        "avg_err = cross_val_multi(x, y, int(len(x)/10))\n",
        "#avg_err = cross_val_multi(x[:100], y[:100], 10)\n",
        "\n",
        "result = {\"task\": [task],\"avg_err\": [avg_err]}\n",
        "df = pd.DataFrame(result, columns = [\"task\",\"avg_err\"])\n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/ML/result/svm_linear_multi_old.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch: 0\n",
            "building predictor for 0\n",
            "building predictor for 1\n",
            "building predictor for 2\n",
            "building predictor for 3\n",
            "building predictor for 4\n",
            "building predictor for 5\n",
            "building predictor for 6\n",
            "building predictor for 7\n",
            "building predictor for 8\n",
            "building predictor for 9\n",
            "predicting\n",
            "error_rate: 0.9042735042735043\n",
            "***************************\n",
            "batch: 1\n",
            "building predictor for 0\n",
            "building predictor for 1\n",
            "building predictor for 2\n",
            "building predictor for 3\n",
            "building predictor for 4\n",
            "building predictor for 5\n",
            "building predictor for 6\n",
            "building predictor for 7\n",
            "building predictor for 8\n",
            "building predictor for 9\n",
            "predicting\n",
            "error_rate: 0.8931623931623932\n",
            "***************************\n",
            "batch: 2\n",
            "building predictor for 0\n",
            "building predictor for 1\n",
            "building predictor for 2\n",
            "building predictor for 3\n",
            "building predictor for 4\n",
            "building predictor for 5\n",
            "building predictor for 6\n",
            "building predictor for 7\n",
            "building predictor for 8\n",
            "building predictor for 9\n",
            "predicting\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrcDF29-bPQj"
      },
      "source": [
        "import numpy as np\n",
        "from functools import lru_cache\n",
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.utils import shuffle\n",
        "import os\n",
        "from functools import lru_cache\n",
        "\n",
        "class svm_new():\n",
        "    def __init__(self, kernel=\"rbf\", lmd=1e-1, sigma=0.1, max_iter=100):\n",
        "        self.kernel = kernel\n",
        "        self.lmd = lmd\n",
        "        self.sigma = sigma\n",
        "        self.max_iter = max_iter\n",
        "        self.alpha = 0\n",
        "        self.w = 0\n",
        "\n",
        "\n",
        "    def kernel_matrix(self, X):\n",
        "        if self.kernel == \"linear\":\n",
        "            return X.dot(X.T)\n",
        "        elif self.kernel == \"rbf\":\n",
        "            return X.dot(X.T)\n",
        "        else:\n",
        "            row, col = X.shape\n",
        "            GassMatrix = np.zeros(shape=(row, row))\n",
        "            i = 0\n",
        "            for v_i in X:\n",
        "                j = 0\n",
        "                for v_j in X:\n",
        "                    GassMatrix[i, j] = Gaussian(v_i.T, v_j.T, self.sigma)\n",
        "                    j += 1\n",
        "                i += 1\n",
        "            return GassMatrix\n",
        "\n",
        "    def Gaussian(self, x, z):\n",
        "        norm = np.linalg.norm(x - z)**2\n",
        "        up = ((norm**2)*-1)\n",
        "        down = (2 * (self.sigma ** 2))\n",
        "        return math.exp(up/down)\n",
        "\n",
        "    def KRR(self, K,y):\n",
        "        m,n = K.shape\n",
        "        return np.linalg.inv(K + np.dot(self.lmd,np.identity(m))).dot(y)\n",
        "\n",
        "\n",
        "    def fit(self, X, y, lamb=0.01, alpha_init=None, eta=0.01, max_step=1000):\n",
        "        \"\"\"\n",
        "        Compute the optimal alpha for an SVM using the kernel matrix K\n",
        "        and observations y.\n",
        "        alpha_init : our initial value for alpha\n",
        "        eta: step size\n",
        "        \"\"\"\n",
        "\n",
        "        K = self.kernel_matrix(X)\n",
        "        n = len(y)\n",
        "        if alpha_init is None:\n",
        "            alpha_init = np.zeros(n)\n",
        "        assert K.shape == (n, n)\n",
        "        assert len(alpha_init) == n\n",
        "        # make sure all labels are +/ - 1 and that we have\n",
        "        # both positive and negative labels\n",
        "        assert (np.unique(y) == np.array([-1, 1])).all()\n",
        "        alpha_k = alpha_init\n",
        "        for k in range(max_step):\n",
        "            if k == 0 or (k+1)%10 == 0:\n",
        "                print(k+1)\n",
        "            alpha_old = alpha_k\n",
        "            ## your code here to update alpha_k\n",
        "            res = np.zeros(n)\n",
        "            for i in range(n):\n",
        "                if y[i] * K[:, i].T.dot(alpha_old) < 1:\n",
        "                    res += np.identity(n).dot(-y[i] * K[:, i])\n",
        "            res += 2 * lamb * K.dot(alpha_old)\n",
        "\n",
        "            alpha_k = alpha_old - eta * res\n",
        "            # # compute y_est\n",
        "            # y_est = (K + lamb * np.identity(n)).dot(alpha_k)\n",
        "            # accuracy = np.mean((y_est > 0) == (y > 0))\n",
        "            alpha_norm_change = np.linalg.norm(alpha_k - alpha_old)\n",
        "            # print(\"k = {:5}\".format(k) + \",alpha_norm_change = {:3.2f}\".format(alpha_norm_change) +\n",
        "            #       \",accuracy = {:3.1f}\".format(accuracy * 100))\n",
        "            if alpha_norm_change < 1e-1:\n",
        "                break\n",
        "        self.alpha = alpha_k\n",
        "        self.w = X.T.dot(alpha_k)\n",
        "        return alpha_k, self.w\n",
        "\n",
        "    def predict (self, X):\n",
        "        \"\"\"\n",
        "        y_predict = []\n",
        "        for s in X.dot(self.w.T):\n",
        "            if s[0] >= 0.:\n",
        "                y_predict.append(1)\n",
        "            else:\n",
        "                y_predict.append(-1)\n",
        "\n",
        "        return np.array(y_predict)\n",
        "        \"\"\"\n",
        "        return X.dot(self.w.T)\n",
        "\n",
        "\n",
        "def cross_val_rbf(X, y, batch_size):\n",
        "    error_arr = []\n",
        "    subset_num = int(len(X)/batch_size)-1\n",
        "    for i in range(subset_num):\n",
        "        print('batch: '+str(i))\n",
        "        error = 0\n",
        "        X_test = X[i*batch_size: (i+1)*batch_size]\n",
        "        y_test = y[i*batch_size: (i+1)*batch_size]\n",
        "        X_train = np.concatenate((X[0: i*batch_size], X[(i+1)*batch_size: len(X)]))\n",
        "        y_train = np.concatenate((y[0: i*batch_size], y[(i+1)*batch_size: len(y)]))\n",
        "        \n",
        "        # Revised part, PCA fitting only applied to training set\n",
        "        pca = PCA()\n",
        "        X_train =  pca.fit_transform(X_train)\n",
        "        X_test = pca.transform(X_test)\n",
        "\n",
        "        print('training')\n",
        "        cf = svm_new(kernel=\"rbf\")\n",
        "        cf.fit(X_train, y_train)\n",
        "\n",
        "        print('predicting')\n",
        "        y_score = cf.predict((X_test))\n",
        "        result = []\n",
        "        for s in y_score:\n",
        "            if s >= 0.:\n",
        "                result.append(1)\n",
        "            else:\n",
        "                result.append(-1)\n",
        "\n",
        "        for i in range(len(X_test)):\n",
        "            if result[i] != y_test[i]:\n",
        "                error = error + 1\n",
        "        error_rate = error/batch_size\n",
        "        error_arr.append(error_rate)\n",
        "    \n",
        "#     print (\"Error rate of each iteration: \" + str(error_arr))\n",
        "    print (\"Average error rate:\" + str(np.average(error_arr)))\n",
        "    print()\n",
        "    \n",
        "    return np.average(error_arr)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh75qKIIcZyt",
        "outputId": "22759daf-3b57-452b-da66-2b035ec0e515"
      },
      "source": [
        "# Binary tasks\n",
        "PATH = \"/content/drive/MyDrive/ML/data_binary\"\n",
        "file_list = os.listdir(PATH)\n",
        "file_list.sort()\n",
        "task = []\n",
        "result = []\n",
        "\n",
        "for file in file_list:\n",
        "    data = np.load(os.path.join(PATH, file))\n",
        "    X = data['x']\n",
        "    y = data['y']\n",
        "    print(file)\n",
        "    avg_err = cross_val_rbf(X, y, int(len(X)/10))\n",
        "    task.append(file.split(\".\")[0])\n",
        "    result.append(avg_err)\n",
        "\n",
        "result_df = {\"task\": task,\"avg_err\": result}\n",
        "df = pd.DataFrame(result_df, columns = [\"task\",\"avg_err\"])\n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/ML/result/svm_rbf_binary.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all_0_vs_rest.npz\n",
            "batch: 0\n",
            "training\n",
            "predicting\n",
            "batch: 1\n",
            "training\n",
            "predicting\n",
            "batch: 2\n",
            "training\n",
            "predicting\n",
            "batch: 3\n",
            "training\n",
            "predicting\n",
            "batch: 4\n",
            "training\n",
            "predicting\n",
            "batch: 5\n",
            "training\n",
            "predicting\n",
            "batch: 6\n",
            "training\n",
            "predicting\n",
            "batch: 7\n",
            "training\n",
            "predicting\n",
            "batch: 8\n",
            "training\n",
            "predicting\n",
            "Average error rate:0.13383838383838384\n",
            "\n",
            "all_1_vs_rest.npz\n",
            "batch: 0\n",
            "training\n",
            "predicting\n",
            "batch: 1\n",
            "training\n",
            "predicting\n",
            "batch: 2\n",
            "training\n",
            "predicting\n",
            "batch: 3\n",
            "training\n",
            "predicting\n",
            "batch: 4\n",
            "training\n",
            "predicting\n",
            "batch: 5\n",
            "training\n",
            "predicting\n",
            "batch: 6\n",
            "training\n",
            "predicting\n",
            "batch: 7\n",
            "training\n",
            "predicting\n",
            "batch: 8\n",
            "training\n",
            "predicting\n",
            "Average error rate:0.12794612794612792\n",
            "\n",
            "all_2_vs_rest.npz\n",
            "batch: 0\n",
            "training\n",
            "predicting\n",
            "batch: 1\n",
            "training\n",
            "predicting\n",
            "batch: 2\n",
            "training\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n",
            "210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgRS5JyjeFia"
      },
      "source": [
        "# Classify 10 different digit classes\n",
        "def cross_val_multi_rbf(X, y, batch_size):\n",
        "    error_arr = []\n",
        "    subset_num = int(len(X)/batch_size)-1\n",
        "    \n",
        "    for i in range(subset_num):\n",
        "        print(\"batch: \" + str(i))\n",
        "        error = 0\n",
        "        X_test = X[i * batch_size: (i + 1) * batch_size]\n",
        "        y_test = y[i * batch_size: (i + 1) * batch_size]\n",
        "        X_train = np.concatenate((X[0: i * batch_size], X[(i + 1) * batch_size: len(X)]))\n",
        "        label_train = np.concatenate((y[0: i * batch_size], y[(i + 1) * batch_size: len(y)]))\n",
        "        \n",
        "        \n",
        "        svm_list = []\n",
        "        for m in range(10):\n",
        "            print('building predictor for ' + str(m))\n",
        "            y_train = []\n",
        "            for j in range(len(label_train)):\n",
        "                if label_train[j] == i:\n",
        "                    y_train.append([1])\n",
        "                else:\n",
        "                    y_train.append([-1])\n",
        "            y_train = np.array(y_train)\n",
        "                    \n",
        "            pca = PCA()\n",
        "            X_train =  pca.fit_transform(X_train)\n",
        "            X_test = pca.transform(X_test)\n",
        "\n",
        "\n",
        "            cf = svm_new(kernel=\"rbf\")\n",
        "            cf.fit(X_train, y_train)\n",
        "            svm_list.append(cf)\n",
        "\n",
        "\n",
        "        print('predicting')\n",
        "        scores = np.zeros((len(svm_list),len(X_test)))\n",
        "        for i in range(len(svm_list)):\n",
        "            scores[i] = np.array(svm_list[i].predict((X_test))).flatten()\n",
        "\n",
        "        scores = scores.T\n",
        "        result = []\n",
        "        for j in range(len(y_test)):\n",
        "            result.append(np.abs(scores[j] - 1).argmin())\n",
        "            \n",
        "        for j in range(len(result)):\n",
        "            if result[j] != y_test[j]:\n",
        "                error = error + 1\n",
        "        \n",
        "        error_rate = error / batch_size\n",
        "        error_arr.append(error_rate)\n",
        "        print('error_rate: '+str(error_rate))\n",
        "        print('***************************')\n",
        "\n",
        "#     print(\"Error rate of each iteration: \" + str(error_arr))\n",
        "    print(\"Average error rate:\" + str(np.average(error_arr)))\n",
        "    return np.average(error_arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "s-bDB1HEcfNG",
        "outputId": "426e45b5-d70d-44ca-97df-ce78aa44434b"
      },
      "source": [
        "# Multiclass tasks\n",
        "task = \"classify 10 digit seeing\"\n",
        "data = np.load(\"/content/drive/MyDrive/ML/data_multi/all_raw_digit.npz\") \n",
        "x = data['x']\n",
        "y = data['y']\n",
        "\n",
        "\n",
        "avg_err = cross_val_multi_rbf(x, y, int(len(x)/10))\n",
        "#avg_err = cross_val_multi_rbf(x[:100], y[:100], 10)\n",
        "\n",
        "result = {\"task\": [task],\"avg_err\": [avg_err]}\n",
        "df = pd.DataFrame(result, columns = [\"task\",\"avg_err\"])\n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/ML/result/svm_rbf_multi.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch: 0\n",
            "building predictor for 0\n",
            "1\n",
            "building predictor for 1\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f9169eab98f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mavg_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_multi_rbf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m#avg_err = cross_val_multi_rbf(x[:100], y[:100], 10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-e3b3074f4b9b>\u001b[0m in \u001b[0;36mcross_val_multi_rbf\u001b[0;34m(X, y, batch_size)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mcf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rbf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0msvm_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-c56b71184104>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, lamb, alpha_init, eta, max_step)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_old\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                     \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlamb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(n, dtype)\u001b[0m\n\u001b[1;32m   2112\u001b[0m     \"\"\"\n\u001b[1;32m   2113\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meye\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2114\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/twodim_base.py\u001b[0m in \u001b[0;36meye\u001b[0;34m(N, M, k, dtype, order)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mM\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}