{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mne\n",
    "import pywt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import antropy as ant\n",
    "\n",
    "from os import listdir\n",
    "# from entropy import *\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.stats import entropy\n",
    "from multiprocessing import Pool\n",
    "from pyrqa.settings import Settings\n",
    "from pyrqa.analysis_type import Classic\n",
    "from pyrqa.time_series import TimeSeries\n",
    "from pyrqa.neighbourhood import FixedRadius\n",
    "from pyrqa.metric import EuclideanMetric\n",
    "from pyrqa.computation import RQAComputation\n",
    "from dit.other import renyi_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_mindbig(data, channel_num, id_num):\n",
    "    \"\"\"Load sample data of MindBigData from the data/ folder.\n",
    "    Args:\n",
    "        id: digit number the subject is seeing and thinking during the experiment. \n",
    "        Should be a number between 0 and 9 or all.\n",
    "    Returns:\n",
    "        all_data: datasets of EEG signals.\n",
    "        all_label: datasets of labels, -1 for rest, 1 for seeing and thinking about a digit.\n",
    "    \"\"\"\n",
    "\n",
    "    data_path = \"./data/\" + data +\".txt\"\n",
    "\n",
    "    data_file = open(data_path, \"r\")\n",
    "    data_lines = data_file.readlines()\n",
    "    \n",
    "\n",
    "    all_data = []\n",
    "    all_label = []\n",
    "\n",
    "    data = [line.split(\"\\t\") for line in data_lines]\n",
    "    data = [i for i in data if i[5] == \"256\"]\n",
    "\n",
    "\n",
    "    if id_num == \"all\":\n",
    "        rest_data = [i for i in data if i[4] == \"-1\"]\n",
    "        math_data = [i for i in data if i[4] != \"-1\"]\n",
    "    else:\n",
    "        rest_data = [i for i in data if i[4] == \"-1\"]\n",
    "        math_data = [i for i in data if i[4] == id_num]\n",
    "\n",
    "    rest_event = np.unique([i[1] for i in rest_data])\n",
    "    math_event = np.unique([i[1] for i in math_data])\n",
    "    \n",
    "    print(len(rest_event))\n",
    "    print(len(math_event))\n",
    "\n",
    "#     rest_event = np.unique([i[1] for i in rest_data])\n",
    "#     math_event = np.unique([i[1] for i in math_data])\n",
    "    \n",
    "    if id_num == \"all\":\n",
    "        math_event = math_event[0 : len(rest_event)]\n",
    "    else:\n",
    "        rest_event = rest_event[0 : len(math_event)]\n",
    "\n",
    "    for event in tqdm(rest_event):\n",
    "        event_data = [\n",
    "            [int(float(k)) for k in i[6].split(\",\")]\n",
    "            for i in rest_data\n",
    "            if i[1] == event\n",
    "        ]\n",
    "        if len(event_data) == channel_num:\n",
    "            all_data.append(event_data)\n",
    "            all_label.append(-1)\n",
    "\n",
    "    for event in tqdm(math_event):\n",
    "        event_data = [\n",
    "            [int(float(k)) for k in i[6].split(\",\")]\n",
    "            for i in math_data\n",
    "            if i[1] == event\n",
    "        ]\n",
    "        if len(event_data) == channel_num:\n",
    "            all_data.append(event_data)\n",
    "            all_label.append(1)\n",
    "\n",
    "    all_data, all_label = shuffle(all_data, all_label)\n",
    "\n",
    "    return all_data, all_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_decompose(data, level, wavelet):\n",
    "    \"\"\"Decompose EEG input into different bands.\n",
    "    Args:\n",
    "        data (numpy.ndarray): array of dimension [number of samples,\n",
    "                number of channels].\n",
    "        level (float): Decomposition level (must be >= 0).\n",
    "        wavelet (str): type of wavelet to use.\n",
    "    Returns:\n",
    "        all_bands (numpy.ndarray): [band frequency, channel\n",
    "            number of bands].\n",
    "    \"\"\"\n",
    "    all_bands = []\n",
    "\n",
    "    for channel in data:\n",
    "        all_bands.append([])\n",
    "        coeffs = pywt.wavedec(channel, wavelet, level=level)\n",
    "        for i in range(len(coeffs)):\n",
    "            if i != 0:\n",
    "                all_bands[len(all_bands) - 1].extend(coeffs[i])\n",
    "\n",
    "    return all_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _renyi_entropy(band):\n",
    "    \"\"\"Compute Renyi entropy.\n",
    "    Renyi entropy is a super class of Shannon entropy when alpha approaches 1.\n",
    "    Here we compute Shannon entropy instead.\n",
    "    Args:\n",
    "        band (numpy.ndarray): one band of samples [band frequency x channel].\n",
    "    Returns:\n",
    "        ren_en: calculated features from Renyi entropy.\n",
    "    \"\"\"\n",
    "\n",
    "    pd_series = pd.Series(band)\n",
    "    counts = pd_series.value_counts()\n",
    "    ren_en = entropy(counts)\n",
    "\n",
    "    return ren_en\n",
    "\n",
    "\n",
    "def _rqa_entropy(band):\n",
    "    \"\"\"Compute RQA entropy.\n",
    "    Args:\n",
    "        band (numpy.ndarray): one band of samples [band frequency x channel].\n",
    "    Returns:\n",
    "        rr, det, entr, lam, tt, vmax, lmax (float): calculated features from RQA entropy.\n",
    "    \"\"\"\n",
    "    time_series = TimeSeries(band, embedding_dimension=2, time_delay=2)\n",
    "    settings = Settings(\n",
    "        time_series,\n",
    "        analysis_type=Classic,\n",
    "        neighbourhood=FixedRadius(0.65),\n",
    "        similarity_measure=EuclideanMetric,\n",
    "        theiler_corrector=1,\n",
    "    )\n",
    "\n",
    "    computation = RQAComputation.create(settings, verbose=False)\n",
    "    result = computation.run()\n",
    "    result.min_diagonal_line_length = 2\n",
    "    result.min_vertical_line_length = 2\n",
    "    result.min_white_vertical_line_length = 2\n",
    "\n",
    "    rr = result.recurrence_rate\n",
    "    det = result.determinism\n",
    "    entr = result.entropy_diagonal_lines\n",
    "    lam = result.laminarity\n",
    "    tt = result.trapping_time\n",
    "    vmax = result.longest_vertical_line\n",
    "    lmax = result.longest_diagonal_line\n",
    "\n",
    "    return rr, det, entr, lam, tt, vmax, lmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(all_bands):\n",
    "    \"\"\"Compute entropy for each bands.\n",
    "    Args:\n",
    "        all-bands data after reshape (numpy.ndarray): [band frequency x channel,\n",
    "            number of designated bands].\n",
    "    Returns:\n",
    "        entropy_output (numpy.ndarray):  [number of entropy features, number of bands].\n",
    "    \"\"\"\n",
    "    entropy_output = []\n",
    "    for band in all_bands:\n",
    "        band = np.nan_to_num(band)\n",
    "        # Approximate entropy\n",
    "        ap_en = ant.app_entropy(band, order=2, metric=\"chebyshev\")\n",
    "\n",
    "        # Sample entropy\n",
    "        samp_en = ant.sample_entropy(band, order=2, metric=\"chebyshev\")\n",
    "\n",
    "        # Renyi entropy\n",
    "#         ren_en = _renyi_entropy(band)\n",
    "\n",
    "        # Recurrence quantification analysis\n",
    "        rr, det, entr, lam, tt, vmax, lmax = _rqa_entropy(band)\n",
    "        entropy_all = [\n",
    "            ap_en,\n",
    "            samp_en,\n",
    "#             ren_en,\n",
    "            rr,\n",
    "            det,\n",
    "            entr,\n",
    "            lam,\n",
    "            tt,\n",
    "            vmax,\n",
    "            lmax,\n",
    "        ]\n",
    "        entropy_all = np.nan_to_num(entropy_all)\n",
    "        entropy_output.extend(entropy_all)\n",
    "\n",
    "    return entropy_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pca(data):\n",
    "    pca = PCA()\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 43/159 [00:00<00:00, 423.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n",
      "1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159/159 [00:00<00:00, 382.23it/s]\n",
      "100%|██████████| 1191/1191 [00:05<00:00, 217.91it/s]\n"
     ]
    }
   ],
   "source": [
    "all_data, all_label = load_data_mindbig(\"EP\", 14, \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1350"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1350/1350 [07:43<00:00,  2.92it/s]\n"
     ]
    }
   ],
   "source": [
    "eeg_data = []\n",
    "\n",
    "for batch in tqdm(all_data):\n",
    "    all_bands = wavelet_decompose(batch, 6, \"db1\")\n",
    "    entropy = compute_entropy(all_bands)\n",
    "    eeg_data.append(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1350"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eeg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data_pca = compute_pca(eeg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.33247506e+00,  9.94008319e-02, -1.06060955e+00,  4.58340343e-01,\n",
       "       -1.53945705e+00,  5.21759908e-01,  9.57227783e-01,  9.65017346e-01,\n",
       "       -1.57717335e+00, -1.00191902e+00,  9.41031013e-01, -1.10487599e+00,\n",
       "       -4.39180363e-01,  2.00299042e-01,  4.59814222e-01,  1.20951446e-01,\n",
       "       -4.15500966e-01, -1.92630498e-02, -2.67060010e-01, -3.73799702e-01,\n",
       "       -7.02585150e-02,  6.98805823e-01, -3.60762909e-01, -5.34739717e-01,\n",
       "        1.96206938e-01,  2.62714919e-01,  3.34480039e-02, -2.99003190e-01,\n",
       "        4.37109601e-02,  7.89702091e-01, -2.30884574e-01,  9.90636042e-02,\n",
       "       -9.02029063e-02,  8.23898602e-02,  6.09751706e-04,  2.71662172e-02,\n",
       "        2.61997873e-01, -1.63633036e-01, -5.55311006e-02, -5.94119860e-02,\n",
       "       -1.37976545e-02, -2.52759027e-02, -1.26044470e-01, -1.10433241e-01,\n",
       "        1.54887168e-02, -8.67239153e-02, -1.13847962e-01, -1.18544441e-02,\n",
       "        5.45227679e-03,  2.66160049e-02,  1.06657817e-02,  2.58912815e-02,\n",
       "       -2.62971244e-04, -4.18579696e-02,  6.50682585e-02, -2.60420704e-02,\n",
       "        3.90958179e-03,  2.90921632e-03, -4.87291295e-02,  2.36951649e-02,\n",
       "       -1.10153104e-03, -2.12448794e-02,  2.74556399e-02,  6.65261697e-02,\n",
       "        5.08704065e-03,  8.50876836e-03,  7.29391289e-03, -1.81041774e-02,\n",
       "       -3.80386963e-02, -6.63105539e-03,  2.94512575e-02,  2.19777770e-02,\n",
       "       -1.57130325e-02, -2.54880129e-02,  4.87084098e-03, -8.04054432e-03,\n",
       "        1.26093730e-02,  8.76508165e-03, -3.34250616e-03,  5.74609405e-03,\n",
       "       -6.79396118e-04,  4.61953595e-03, -7.58212422e-03, -4.26941309e-03,\n",
       "       -8.96848031e-03,  4.92211675e-03,  2.39402986e-03,  1.49526694e-03,\n",
       "       -1.96900618e-03, -4.14298999e-04, -1.07993764e-03, -6.68040980e-04,\n",
       "       -1.53485702e-03, -1.21917544e-03, -3.22995480e-03, -3.63978732e-04,\n",
       "       -1.71046724e-03, -7.70494350e-04, -5.51473423e-04, -1.65741404e-03,\n",
       "        3.02148373e-03,  1.39036036e-03, -2.34607029e-03,  2.46795757e-03,\n",
       "        2.39233291e-03,  7.28591201e-03, -9.51780515e-04,  1.42816770e-03,\n",
       "        1.81634084e-04, -3.73146220e-04, -8.81938852e-04,  5.02393895e-04,\n",
       "       -3.16183767e-05, -8.85804666e-04, -2.15242834e-04,  1.24346652e-05,\n",
       "       -5.85965585e-04, -7.83488554e-04,  2.98781477e-04, -4.75634099e-04,\n",
       "        2.81053124e-05,  1.70993733e-06, -3.72735040e-04,  4.11501963e-04,\n",
       "       -1.14921742e-17,  2.69768175e-18])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg_data_pca[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y):\n",
    "    w = np.linalg.inv((X.transpose() @ X)) @ (X.transpose() @ y)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w):\n",
    "    raw_val = X.transpose() @ w\n",
    "    \n",
    "    if raw_val >= 0:\n",
    "        return 1\n",
    "    if raw_val < 0:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'y']\n"
     ]
    }
   ],
   "source": [
    "with np.load('eeg_data.npz') as data:\n",
    "    print(data.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"eeg_data.npz\")\n",
    "X = data['x']\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
