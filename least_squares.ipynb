{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import warnings \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with specific id number\n",
    "def load_data(id_num, not_id=False, no_rest=False):\n",
    "    data = np.load(\"./data_old/eeg_data_shuffle.npz\")\n",
    "    X = data['x']\n",
    "    y = data['y']\n",
    "    \n",
    "    if not_id:\n",
    "        if no_rest:\n",
    "            index = [i for i in range(len(y)) if y[i] != id_num and y[i] != -1]\n",
    "        else:\n",
    "            index = [i for i in range(len(y)) if y[i] != id_num]\n",
    "    else:\n",
    "        index = [i for i in range(len(y)) if y[i] == id_num]\n",
    "    \n",
    "    output_data = []\n",
    "    output_label = []\n",
    "    \n",
    "    for i in index:\n",
    "        output_data.append(X[i])\n",
    "        output_label.append(y[i])\n",
    "        \n",
    "    return output_data, output_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare seeing one number with rest \n",
    "def binary_all_channel(data, label, assigned_y):\n",
    "    if len(data) != len(label):\n",
    "        print(\"Something is wrong here\")\n",
    "        return\n",
    "    \n",
    "    output_data = []\n",
    "    output_label = []\n",
    "    \n",
    "    for i in range(len(label)):\n",
    "        output_label.append([assigned_y])\n",
    "  \n",
    "        feature = np.concatenate(data[i])\n",
    "        feature = np.nan_to_num(feature)\n",
    "        output_data.append(feature)\n",
    "        \n",
    "    return output_data, output_label    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_selected_channel(data, label, assigned_y, brain_region): \n",
    "    output_data = []\n",
    "    output_label = []\n",
    "    channel_list = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\n",
    "    \n",
    "    if len(data) != len(label):\n",
    "        print(\"Something is wrong here\")\n",
    "        return\n",
    "    if brain_region == \"frontal\":\n",
    "        index = [i for i in range(len(channel_list)) if 'F' in channel_list[i]]\n",
    "    if brain_region == \"temporal\":\n",
    "        index = [i for i in range(len(channel_list)) if 'T' in channel_list[i]]\n",
    "    if brain_region == \"parietal\":\n",
    "        index = [i for i in range(len(channel_list)) if 'P' in channel_list[i]]\n",
    "    if brain_region == \"occipital\":\n",
    "        index = [i for i in range(len(channel_list)) if 'O' in channel_list[i]]\n",
    "    \n",
    "    for i in range(len(label)):\n",
    "        output_label.append([assigned_y])\n",
    "        feature = data[i][index[0]]\n",
    "        for k in index[1:]:\n",
    "            feature = np.append(feature, data[i][k])\n",
    "        feature = np.nan_to_num(feature)\n",
    "        output_data.append(feature)\n",
    "        \n",
    "    return output_data, output_label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_all_channel(data, label, id_num):\n",
    "    if len(data) != len(label):\n",
    "        print(\"Something is wrong here\")\n",
    "        return\n",
    "    \n",
    "    output_data = []\n",
    "    output_label = []\n",
    "    \n",
    "    for i in range(len(label)):\n",
    "        if label[i] != id_num and label[i] != -1:\n",
    "            print(\"Something is wrong here\")\n",
    "            break\n",
    "        output_label.append([label[i]])\n",
    "        feature = np.concatenate(data[i])\n",
    "        feature = np.nan_to_num(feature)\n",
    "        output_data.append(feature)\n",
    "        \n",
    "    return output_data, output_label    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(X, y):\n",
    "    w = np.linalg.inv((X.transpose() @ X)) @ (X.transpose() @ y)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_least_squares(X, y, k):\n",
    "    u, s, vh = np.linalg.svd(X, full_matrices=True)\n",
    "    if k == -2:\n",
    "        s_ridged = [i/(i**2+0) for i in s]\n",
    "    else:\n",
    "        s_ridged = [i/(i**2+2**k) for i in s]\n",
    "    \n",
    "    s_matrix_ridged = np.zeros((vh.shape[0], u.shape[0]), float)\n",
    "    np.fill_diagonal(s_matrix_ridged, s_ridged)\n",
    "    \n",
    "    w = vh.transpose() @ s_matrix_ridged @ u.transpose() @ y\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, mode):\n",
    "    raw_val = X.transpose() @ w\n",
    "    \n",
    "    if mode == \"binary\":\n",
    "        if raw_val >= 0:\n",
    "            return 1\n",
    "        if raw_val < 0:\n",
    "            return -1\n",
    "    if mode == \"multiclass\":\n",
    "        return raw_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cross_val(X, y, batch_size, classifier):\n",
    "    error_arr = []\n",
    "    subset_num = int(len(X)/batch_size)-1\n",
    "    for i in range(subset_num):\n",
    "        error = 0\n",
    "        X_test = X[i*batch_size: (i+1)*batch_size]\n",
    "        y_test = y[i*batch_size: (i+1)*batch_size]\n",
    "        X_train = np.concatenate((X[0: i*batch_size], X[(i+1)*batch_size: len(X)]))\n",
    "        y_train = np.concatenate((y[0: i*batch_size], y[(i+1)*batch_size: len(y)]))\n",
    "        \n",
    "        pca = PCA()\n",
    "        X_train =  pca.fit_transform(X_train)\n",
    "        X_test = pca.transform(X_test)\n",
    "    \n",
    "        \n",
    "        w = least_squares(X_train, y_train)\n",
    "        for i in range(len(X_test)):\n",
    "            result = predict(X_test[i], w, classifier)\n",
    "            if result != y_test[i]:\n",
    "                error = error + 1\n",
    "        error_rate = error/batch_size\n",
    "        error_arr.append(error_rate)\n",
    "        \n",
    "#     print (\"Error rate of each iteration: \" + str(error_arr))\n",
    "    print (\"Average error rate:\" + str(np.average(error_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pca(data):\n",
    "    pca = PCA()\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    return pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_shuffle_data():\n",
    "    all_data, all_label = load_data(-1)\n",
    "    \n",
    "    for i in range(0, 10):\n",
    "        data, label= load_data(i)\n",
    "        data, label = shuffle(data, label)\n",
    "        data = data[0:1170]\n",
    "        label = label[0:1170]\n",
    "        \n",
    "        all_data = np.concatenate((all_data, data))\n",
    "        all_label = np.concatenate((all_label, label))\n",
    "    \n",
    "    all_data, all_label = shuffle(all_data, all_label)\n",
    "\n",
    "    return all_data, all_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data, all_label = save_shuffle_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./data_old/eeg_data_shuffle', x=all_data, y=all_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify rest and seeing any number\n",
    "# channel = [\"all\", \"frontal\", \"temporal\", \"parietal\", \"occipital\"]\n",
    "def rest_verses_all_number(channel):\n",
    "    class_1 = -1\n",
    "    class_2 = -1\n",
    "\n",
    "    data_1, label_1= load_data(class_1)\n",
    "    if channel == \"all\":\n",
    "        data_1, label_1 = binary_all_channel(data_1, label_1, 1)\n",
    "    else: \n",
    "        data_1, label_1 = binary_selected_channel(data_1, label_1, 1, channel) \n",
    "            \n",
    "    data_2, label_2 = load_data(class_2, not_id=True)\n",
    "    if channel == \"all\":\n",
    "        data_2, label_2 = binary_all_channel(data_2, label_2, -1)\n",
    "    else:\n",
    "        data_2, label_2 = binary_selected_channel(data_2, label_2, -1, channel)\n",
    "\n",
    "    X = np.concatenate((data_1, data_2))\n",
    "    y = np.concatenate((label_1, label_2))\n",
    "\n",
    "    X_normalized = sklearn.preprocessing.normalize(X, norm='l2')\n",
    "#     X_pca = compute_pca(X_normalized)\n",
    "\n",
    "    all_data, all_label = shuffle(X_normalized, y)\n",
    "    np.savez(\"data_shuffle/\"+ channel +\"_\" + \"all\" + \"_\" + \"vs\" +\"_\"+ \"rest\", x=all_data, y=all_label)\n",
    "    \n",
    "    print(\"Digit 0 ~ 9 verses rest\")\n",
    "    cross_val(all_data, all_label, int(len(all_data)/10), \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_verses_all_number(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify rest and a number n (0-9)\n",
    "def rest_verses_single_number(channel):\n",
    "    for i in range(10):\n",
    "        data_rest, label_rest = load_data(-1)\n",
    "        if channel == \"all\":\n",
    "            data_rest, label_rest = binary_all_channel(data_rest, label_rest, 1)\n",
    "        else:\n",
    "            data_rest, label_rest = binary_selected_channel(data_rest, label_rest, 1, channel) \n",
    "\n",
    "        data_num, label_num = load_data(i)\n",
    "        \n",
    "        if channel == \"all\":\n",
    "            data_num, label_num = binary_all_channel(data_num, label_num, -1)\n",
    "        else:\n",
    "             data_num, label_num = binary_selected_channel(data_num, label_num, -1, channel) \n",
    "\n",
    "        X = np.concatenate((data_rest, data_num))\n",
    "        y = np.concatenate((label_rest, label_num))\n",
    "\n",
    "        X_normalized = sklearn.preprocessing.normalize(X, norm='l2')\n",
    "        \n",
    "        all_data, all_label = shuffle(X_normalized, y)\n",
    "        np.savez(\"data_shuffle/\"+ channel +\"_\" + str(i) + \"_\" + \"vs\" +\"_\"+ \"rest\", x=all_data, y=all_label)\n",
    "        \n",
    "\n",
    "        print(\"Digit \" + str(i) + \" verses rest\")\n",
    "        cross_val(all_data, all_label, int(len(all_data)/10), \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\n",
      "Digit 0 ~ 9 verses rest\n",
      "Average error rate:0.43928738865447725\n",
      "Digit 0 verses rest\n",
      "Average error rate:0.24915824915824913\n",
      "Digit 1 verses rest\n",
      "Average error rate:0.234006734006734\n",
      "Digit 2 verses rest\n",
      "Average error rate:0.19191919191919193\n",
      "Digit 3 verses rest\n",
      "Average error rate:0.29461279461279455\n",
      "Digit 4 verses rest\n",
      "Average error rate:0.2601010101010101\n",
      "Digit 5 verses rest\n",
      "Average error rate:0.2617845117845118\n",
      "Digit 6 verses rest\n",
      "Average error rate:0.2617845117845118\n",
      "Digit 7 verses rest\n",
      "Average error rate:0.28787878787878785\n",
      "Digit 8 verses rest\n",
      "Average error rate:0.28367003367003363\n",
      "Digit 9 verses rest\n",
      "Average error rate:0.2095959595959596\n",
      "frontal\n",
      "Digit 0 ~ 9 verses rest\n",
      "Average error rate:0.4123769338959213\n",
      "Digit 0 verses rest\n",
      "Average error rate:0.28114478114478114\n",
      "Digit 1 verses rest\n",
      "Average error rate:0.20033670033670034\n",
      "Digit 2 verses rest\n",
      "Average error rate:0.18265993265993266\n",
      "Digit 3 verses rest\n",
      "Average error rate:0.2525252525252525\n",
      "Digit 4 verses rest\n",
      "Average error rate:0.20538720538720537\n",
      "Digit 5 verses rest\n",
      "Average error rate:0.24494949494949494\n",
      "Digit 6 verses rest\n",
      "Average error rate:0.19612794612794612\n",
      "Digit 7 verses rest\n",
      "Average error rate:0.24579124579124578\n",
      "Digit 8 verses rest\n",
      "Average error rate:0.2062289562289562\n",
      "Digit 9 verses rest\n",
      "Average error rate:0.21632996632996632\n",
      "temporal\n",
      "Digit 0 ~ 9 verses rest\n",
      "Average error rate:0.47679324894514763\n",
      "Digit 0 verses rest\n",
      "Average error rate:0.34175084175084175\n",
      "Digit 1 verses rest\n",
      "Average error rate:0.2676767676767676\n",
      "Digit 2 verses rest\n",
      "Average error rate:0.25420875420875416\n",
      "Digit 3 verses rest\n",
      "Average error rate:0.28787878787878785\n",
      "Digit 4 verses rest\n",
      "Average error rate:0.36447811447811446\n",
      "Digit 5 verses rest\n",
      "Average error rate:0.2861952861952862\n",
      "Digit 6 verses rest\n",
      "Average error rate:0.25841750841750843\n",
      "Digit 7 verses rest\n",
      "Average error rate:0.2861952861952861\n",
      "Digit 8 verses rest\n",
      "Average error rate:0.25757575757575757\n",
      "Digit 9 verses rest\n",
      "Average error rate:0.2962962962962963\n",
      "parietal\n",
      "Digit 0 ~ 9 verses rest\n",
      "Average error rate:0.4746366619784341\n",
      "Digit 0 verses rest\n",
      "Average error rate:0.414983164983165\n",
      "Digit 1 verses rest\n",
      "Average error rate:0.38383838383838387\n",
      "Digit 2 verses rest\n",
      "Average error rate:0.3813131313131313\n",
      "Digit 3 verses rest\n",
      "Average error rate:0.4074074074074074\n",
      "Digit 4 verses rest\n",
      "Average error rate:0.42003367003367\n",
      "Digit 5 verses rest\n",
      "Average error rate:0.37373737373737376\n",
      "Digit 6 verses rest\n",
      "Average error rate:0.40824915824915825\n",
      "Digit 7 verses rest\n",
      "Average error rate:0.3813131313131313\n",
      "Digit 8 verses rest\n",
      "Average error rate:0.3787878787878788\n",
      "Digit 9 verses rest\n",
      "Average error rate:0.4225589225589226\n",
      "occipital\n",
      "Digit 0 ~ 9 verses rest\n",
      "Average error rate:0.5300515705578996\n",
      "Digit 0 verses rest\n",
      "Average error rate:0.4074074074074074\n",
      "Digit 1 verses rest\n",
      "Average error rate:0.4074074074074074\n",
      "Digit 2 verses rest\n",
      "Average error rate:0.3611111111111111\n",
      "Digit 3 verses rest\n",
      "Average error rate:0.39562289562289554\n",
      "Digit 4 verses rest\n",
      "Average error rate:0.4234006734006734\n",
      "Digit 5 verses rest\n",
      "Average error rate:0.40488215488215484\n",
      "Digit 6 verses rest\n",
      "Average error rate:0.3720538720538721\n",
      "Digit 7 verses rest\n",
      "Average error rate:0.3771043771043771\n",
      "Digit 8 verses rest\n",
      "Average error rate:0.3855218855218856\n",
      "Digit 9 verses rest\n",
      "Average error rate:0.36447811447811446\n"
     ]
    }
   ],
   "source": [
    "# Break down by brain region binary\n",
    "for i in [\"all\", \"frontal\", \"temporal\", \"parietal\", \"occipital\"]:\n",
    "    print(i)\n",
    "    rest_verses_all_number(i)\n",
    "    rest_verses_single_number(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PATH = \"./data_shuffle\"\n",
    "lst = os.listdir(PATH)\n",
    "lst.sort()\n",
    "for file in lst:\n",
    "    data = np.load(os.path.join(PATH, file))\n",
    "    X = data['x']\n",
    "    y = data['y']\n",
    "    print(file)\n",
    "    cross_val(X, y, int(len(X)/10), \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify rest and a number n (0-9)\n",
    "def all_but_verses_single_number(channel):\n",
    "    for i in range(10):\n",
    "        data_rest, label_rest = load_data(i)\n",
    "        if channel == \"all\":\n",
    "            data_rest, label_rest = binary_all_channel(data_rest, label_rest, 1)\n",
    "        else:\n",
    "            data_rest, label_rest = binary_selected_channel(data_rest, label_rest, 1, channel) \n",
    "\n",
    "        data_num, label_num = load_data(i, not_id=True, no_rest = True)\n",
    "        \n",
    "        if channel == \"all\":\n",
    "            data_num, label_num = binary_all_channel(data_num, label_num, -1)\n",
    "        else:\n",
    "             data_num, label_num = binary_selected_channel(data_num, label_num, -1, channel) \n",
    "        \n",
    "        print(len(data_rest))\n",
    "        print(len(data_num))\n",
    "\n",
    "        X = np.concatenate((data_rest, data_num))\n",
    "        y = np.concatenate((label_rest, label_num))\n",
    "\n",
    "        X_normalized = sklearn.preprocessing.normalize(X, norm='l2')\n",
    "        X_pca = compute_pca(X_normalized)\n",
    "        \n",
    "        all_data, all_label = shuffle(X_pca, y)\n",
    "        np.savez(\"data_shuffle_multi/\"+ channel +\"_\" + str(i) + \"_\" + \"vs\" +\"_\"+ \"all_other_digit\", x=all_data, y=all_label)\n",
    "        \n",
    "        print(len(all_data))\n",
    "\n",
    "        print(\"Digit \" + str(i) + \" verses all other\")\n",
    "        cross_val(all_data, all_label, int(len(all_data)/10), \"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_but_verses_single_number(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify multiple class (0-9 and rest)\n",
    "X, y = load_data(0)\n",
    "X, y = multiclass_all_channel(X, y, 0)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    data_num, label_num = load_data(i)\n",
    "    data_num, label_num = multiclass_all_channel(data_num, label_num, i)\n",
    "    \n",
    "    X = np.concatenate((X, data_num))\n",
    "    y = np.concatenate((y, label_num))\n",
    "    \n",
    "X_normalized = sklearn.preprocessing.normalize(X, norm='l2')\n",
    "# X_pca = compute_pca(X_normalized)\n",
    "\n",
    "all_data, all_label = shuffle(X_normalized, y)\n",
    "\n",
    "np.savez(\"data_shuffle_multi/\"+ \"all\" +\"_\" + \"raw_digit\", x=all_data, y=all_label)\n",
    "\n",
    "# all_data, all_label = X_pca, y\n",
    "# cross_val(all_data, all_label, 1000, \"multiclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "-i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11700, 350)\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"./data_shuffle_multi/all_raw_digit.npz\") \n",
    "x = data['x']\n",
    "y = data['y']\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1170"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in y if i == 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi(X, y, batch_size):\n",
    "    error_arr = []\n",
    "    subset_num = int(len(X) / batch_size) - 1\n",
    "    \n",
    "    for i in range(subset_num):\n",
    "        print(\"batch: \" + str(i))\n",
    "        error = 0\n",
    "        X_test = X[i * batch_size: (i + 1) * batch_size]\n",
    "        y_test = y[i * batch_size: (i + 1) * batch_size]\n",
    "        X_train = np.concatenate((X[0: i * batch_size], X[(i + 1) * batch_size: len(X)]))\n",
    "        label_train = np.concatenate((y[0: i * batch_size], y[(i + 1) * batch_size: len(y)]))\n",
    "        \n",
    "        weight_list = []\n",
    "        for m in range(10):\n",
    "            print('building predictor for ' + str(m))\n",
    "            y_train = []\n",
    "            for j in range(len(label_train)):\n",
    "                if label_train[j] == i:\n",
    "                    y_train.append([1])\n",
    "                else:\n",
    "                    y_train.append([-1])\n",
    "                    \n",
    "            pca = PCA()\n",
    "            X_train =  pca.fit_transform(X_train)\n",
    "            X_test = pca.transform(X_test)\n",
    "\n",
    "            print('running least squares')\n",
    "            \n",
    "            w = least_squares(X_train, y_train)\n",
    "            weight_list.append(w)\n",
    "\n",
    "        print('predicting')\n",
    "        error = 0\n",
    "        for j in range(len(X_test)):\n",
    "            row_score = []\n",
    "            for k in range(len(weight_list)):\n",
    "                result = predict(X_test[j], weight_list[k], \"multiclass\")\n",
    "                dist = abs(result-1)\n",
    "                row_score.append(dist)\n",
    "                \n",
    "            prediction = np.argmin(row_score)\n",
    "            \n",
    "            if prediction != y_test[j]:\n",
    "                error = error + 1\n",
    "        \n",
    "        error_rate = error / batch_size\n",
    "        error_arr.append(error_rate)\n",
    "        print('error_rate: '+str(error_rate))\n",
    "        print('***************************')\n",
    "\n",
    "#     print(\"Error rate of each iteration: \" + str(error_arr))\n",
    "    print(\"Average error rate:\" + str(np.average(error_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0\n",
      "building predictor for 0\n",
      "running least squares\n",
      "building predictor for 1\n",
      "running least squares\n",
      "building predictor for 2\n",
      "running least squares\n",
      "building predictor for 3\n",
      "running least squares\n",
      "building predictor for 4\n",
      "running least squares\n",
      "building predictor for 5\n",
      "running least squares\n",
      "building predictor for 6\n",
      "running least squares\n",
      "building predictor for 7\n",
      "running least squares\n",
      "building predictor for 8\n",
      "running least squares\n",
      "building predictor for 9\n",
      "running least squares\n",
      "predicting\n",
      "error_rate: 0.9102564102564102\n",
      "***************************\n",
      "batch: 1\n",
      "building predictor for 0\n",
      "running least squares\n",
      "building predictor for 1\n",
      "running least squares\n",
      "building predictor for 2\n",
      "running least squares\n",
      "building predictor for 3\n",
      "running least squares\n",
      "building predictor for 4\n",
      "running least squares\n",
      "building predictor for 5\n",
      "running least squares\n",
      "building predictor for 6\n",
      "running least squares\n",
      "building predictor for 7\n",
      "running least squares\n",
      "building predictor for 8\n",
      "running least squares\n",
      "building predictor for 9\n",
      "running least squares\n",
      "predicting\n",
      "error_rate: 0.911965811965812\n",
      "***************************\n",
      "batch: 2\n",
      "building predictor for 0\n",
      "running least squares\n",
      "building predictor for 1\n",
      "running least squares\n",
      "building predictor for 2\n",
      "running least squares\n",
      "building predictor for 3\n",
      "running least squares\n",
      "building predictor for 4\n",
      "running least squares\n",
      "building predictor for 5\n",
      "running least squares\n",
      "building predictor for 6\n",
      "running least squares\n",
      "building predictor for 7\n",
      "running least squares\n",
      "building predictor for 8\n",
      "running least squares\n",
      "building predictor for 9\n",
      "running least squares\n",
      "predicting\n",
      "error_rate: 0.9128205128205128\n",
      "***************************\n",
      "batch: 3\n",
      "building predictor for 0\n",
      "running least squares\n",
      "building predictor for 1\n",
      "running least squares\n",
      "building predictor for 2\n",
      "running least squares\n",
      "building predictor for 3\n",
      "running least squares\n",
      "building predictor for 4\n",
      "running least squares\n",
      "building predictor for 5\n",
      "running least squares\n",
      "building predictor for 6\n",
      "running least squares\n",
      "building predictor for 7\n",
      "running least squares\n",
      "building predictor for 8\n",
      "running least squares\n",
      "building predictor for 9\n",
      "running least squares\n",
      "predicting\n",
      "error_rate: 0.911965811965812\n",
      "***************************\n",
      "batch: 4\n",
      "building predictor for 0\n",
      "running least squares\n",
      "building predictor for 1\n",
      "running least squares\n",
      "building predictor for 2\n",
      "running least squares\n",
      "building predictor for 3\n",
      "running least squares\n",
      "building predictor for 4\n",
      "running least squares\n",
      "building predictor for 5\n",
      "running least squares\n",
      "building predictor for 6\n",
      "running least squares\n",
      "building predictor for 7\n",
      "running least squares\n",
      "building predictor for 8\n",
      "running least squares\n",
      "building predictor for 9\n",
      "running least squares\n",
      "predicting\n",
      "error_rate: 0.8948717948717949\n",
      "***************************\n",
      "batch: 5\n",
      "building predictor for 0\n",
      "running least squares\n",
      "building predictor for 1\n",
      "running least squares\n",
      "building predictor for 2\n",
      "running least squares\n",
      "building predictor for 3\n",
      "running least squares\n",
      "building predictor for 4\n",
      "running least squares\n",
      "building predictor for 5\n",
      "running least squares\n",
      "building predictor for 6\n",
      "running least squares\n",
      "building predictor for 7\n",
      "running least squares\n",
      "building predictor for 8\n",
      "running least squares\n",
      "building predictor for 9\n",
      "running least squares\n",
      "predicting\n",
      "error_rate: 0.8923076923076924\n",
      "***************************\n",
      "batch: 6\n",
      "building predictor for 0\n",
      "running least squares\n",
      "building predictor for 1\n",
      "running least squares\n",
      "building predictor for 2\n",
      "running least squares\n",
      "building predictor for 3\n",
      "running least squares\n",
      "building predictor for 4\n",
      "running least squares\n",
      "building predictor for 5\n",
      "running least squares\n",
      "building predictor for 6\n",
      "running least squares\n",
      "building predictor for 7\n",
      "running least squares\n",
      "building predictor for 8\n",
      "running least squares\n",
      "building predictor for 9\n",
      "running least squares\n",
      "predicting\n",
      "error_rate: 0.9\n",
      "***************************\n",
      "batch: 7\n",
      "building predictor for 0\n",
      "running least squares\n",
      "building predictor for 1\n",
      "running least squares\n",
      "building predictor for 2\n",
      "running least squares\n",
      "building predictor for 3\n",
      "running least squares\n",
      "building predictor for 4\n",
      "running least squares\n",
      "building predictor for 5\n",
      "running least squares\n",
      "building predictor for 6\n",
      "running least squares\n",
      "building predictor for 7\n",
      "running least squares\n",
      "building predictor for 8\n",
      "running least squares\n",
      "building predictor for 9\n",
      "running least squares\n",
      "predicting\n",
      "error_rate: 0.9111111111111111\n",
      "***************************\n",
      "batch: 8\n",
      "building predictor for 0\n",
      "running least squares\n",
      "building predictor for 1\n",
      "running least squares\n",
      "building predictor for 2\n",
      "running least squares\n",
      "building predictor for 3\n",
      "running least squares\n",
      "building predictor for 4\n",
      "running least squares\n",
      "building predictor for 5\n",
      "running least squares\n",
      "building predictor for 6\n",
      "running least squares\n",
      "building predictor for 7\n",
      "running least squares\n",
      "building predictor for 8\n",
      "running least squares\n",
      "building predictor for 9\n",
      "running least squares\n",
      "predicting\n",
      "error_rate: 0.8846153846153846\n",
      "***************************\n",
      "Average error rate:0.90332383665717\n"
     ]
    }
   ],
   "source": [
    "multi(x, y, int(len(x)/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10*25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-31186e0e982f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "scores = [1,2,3,4,5]\n",
    "np.abs(scores - 1).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
