{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“svm.ipynb”的副本",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMkoEuswHOUcYOersZhben6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YintongMa/EEGDataMining/blob/feat%2Fkernel-svm/%E2%80%9Csvm_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAAhPjLVY-s8"
      },
      "source": [
        "import numpy as np\n",
        "from functools import lru_cache\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "class svm():\n",
        "\n",
        "    def __init__(self,\n",
        "                 kernel=\"rbf\", lmd=1e-1, gamma=0.1, bias=1.0, max_iter=100):\n",
        "        if kernel not in self.__kernel_dict:\n",
        "            print(kernel + \" kernel does not exist!\\nUse rbf kernel.\")\n",
        "            kernel = \"rbf\"\n",
        "        if kernel == \"rbf\":\n",
        "            def kernel_func(x, y):\n",
        "                return self.__kernel_dict[kernel](x, y, gamma=gamma)\n",
        "        else:\n",
        "            kernel_func = self.__kernel_dict[kernel]\n",
        "        self.kernel = kernel_func\n",
        "        self.lmd = lmd\n",
        "        self.bias = bias\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def __linear_kernel(x, y):\n",
        "        return np.dot(x, y)\n",
        "\n",
        "    def __gaussian_kernel(x, y, gamma):\n",
        "        diff = x - y\n",
        "        return np.exp(-gamma * np.dot(diff, diff))\n",
        "\n",
        "    __kernel_dict = {\"linear\": __linear_kernel, \"rbf\": __gaussian_kernel}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        def update_alpha(alpha, t):\n",
        "            data_size, feature_size = np.shape(self.X_with_bias)\n",
        "            new_alpha = np.copy(alpha)\n",
        "            it = np.random.randint(low=0, high=data_size)\n",
        "            x_it = self.X_with_bias[it]\n",
        "            y_it = self.y[it]\n",
        "\n",
        "            # alpha[k] = alpha[k] + eta[k] * (1 - myData.loc[k, 2] * sum(alpha * myData.loc[:, 2] * K[:, k]))\n",
        "            if (y_it * (1. / (self.lmd * t)) * sum([alpha_j * y_it * self.kernel(x_it, x_j) for x_j, alpha_j in zip(self.X_with_bias, alpha)])) < 1.:\n",
        "                new_alpha[it] += 1\n",
        "            return new_alpha\n",
        "\n",
        "        self.X_with_bias = np.c_[X, np.ones((np.shape(X)[0])) * self.bias]\n",
        "        self.y = y\n",
        "        alpha = np.zeros((np.shape(self.X_with_bias)[0], 1))\n",
        "\n",
        "        for t in range(1, self.max_iter + 1):\n",
        "            alpha = update_alpha(alpha, t)\n",
        "        self.alpha = alpha\n",
        "        return alpha\n",
        "\n",
        "\n",
        "    def predict(self,X):\n",
        "        X_with_bias = np.c_[X, np.ones((np.shape(X)[0])) * self.bias]\n",
        "\n",
        "        y_score = []\n",
        "\n",
        "        for x in X_with_bias:\n",
        "            i = 0\n",
        "            for (x_j, y_j, alpha_j) in zip(self.X_with_bias, self.y, self.alpha):\n",
        "                i += alpha_j * y_j * self.kernel(x_j, x)\n",
        "            y_score.append((1. / (self.lmd * self.max_iter)) * i)\n",
        "\n",
        "        y_predict = []\n",
        "        for s in y_score:\n",
        "            if s >= 0.:\n",
        "                y_predict.append(1)\n",
        "            else:\n",
        "                y_predict.append(-1)\n",
        "        return y_predict\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs2RRct6hNGW"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBbJkJxHhNGX"
      },
      "source": [
        "# Load data with specific id number\n",
        "def load_data(id_num):\n",
        "    data = np.load(\"/content/eeg_data.npz\")\n",
        "    X = data['x']\n",
        "    y = data['y']\n",
        "    \n",
        "    index = [i for i in range(len(y)) if y[i] == id_num]\n",
        "    \n",
        "    output_data = []\n",
        "    output_label = []\n",
        "    \n",
        "    for i in index:\n",
        "        output_data.append(X[i])\n",
        "        output_label.append(y[i])\n",
        "        \n",
        "    return output_data, output_label"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzLUUBHchNGY"
      },
      "source": [
        "# Compare seeing one number with rest \n",
        "def binary_all_channel(data, label, id_num):\n",
        "    if len(data) != len(label):\n",
        "        print(\"Something is wrong here\")\n",
        "        return\n",
        "    \n",
        "    output_data = []\n",
        "    output_label = []\n",
        "    \n",
        "    for i in range(len(label)):\n",
        "        if label[i] != id_num and label[i] != -1:\n",
        "            print(\"Something is wrong here\")\n",
        "            break\n",
        "        if label[i] != -1:\n",
        "            output_label.append([1])\n",
        "        else:\n",
        "            output_label.append([-1])\n",
        "        \n",
        "        feature = np.concatenate(data[i])\n",
        "        feature = np.nan_to_num(feature)\n",
        "        output_data.append(feature)\n",
        "        \n",
        "    return output_data, output_label    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQKOFb4RhNGa"
      },
      "source": [
        "def predict(X, w, mode):\n",
        "    raw_val = X.transpose() @ w\n",
        "    \n",
        "    if mode == \"binary\":\n",
        "        if raw_val >= 0:\n",
        "            return 1\n",
        "        if raw_val < 0:\n",
        "            return -1\n",
        "    if mode == \"multiclass\":\n",
        "        return round(raw_val[0])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqILQR3mZnwu"
      },
      "source": [
        "def cross_val(X, y, batch_size):\n",
        "    error_arr = []\n",
        "    subset_num = int(len(X)/batch_size)-1\n",
        "    for i in range(subset_num):\n",
        "        print(\"batch: \" + str(i))\n",
        "        error = 0\n",
        "        X_test = X[i*batch_size: (i+1)*batch_size]\n",
        "        y_test = y[i*batch_size: (i+1)*batch_size]\n",
        "        X_train = np.concatenate((X[0: i*batch_size], X[(i+1)*batch_size: len(X)]))\n",
        "        y_train = np.concatenate((y[0: i*batch_size], y[(i+1)*batch_size: len(y)]))\n",
        "\n",
        "        print('running svm')\n",
        "        cf = svm(kernel=\"linear\")\n",
        "        cf.fit(X_train, y_train)\n",
        "\n",
        "        print('predicting')\n",
        "        result = cf.predict((X_test))\n",
        "        for j in range(len(result)):\n",
        "            if result[j] != y_test[j]:\n",
        "                error = error + 1\n",
        "        error_rate = error/batch_size\n",
        "        error_arr.append(error_rate)\n",
        "\n",
        "        print(\"error rate is \" + str(error_rate))\n",
        "        print()\n",
        "    \n",
        "    print (\"Error rate of each iteration: \" + str(error_arr))\n",
        "    print (\"Average error rate:\" + str(np.average(error_arr)))\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oixiNbWkoQdy"
      },
      "source": [
        "def compute_pca(data):\n",
        "    pca = PCA()\n",
        "    pca_data = pca.fit_transform(data)\n",
        "    return pca_data"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xnl6MW-iOxW",
        "outputId": "2687d78e-963b-4097-b8a6-546154bf85ce"
      },
      "source": [
        "data = np.load(\"/content/eeg_data.npz\")\n",
        "data_x = data['x']\n",
        "data_y = data['y']\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(len(data_y)):\n",
        "    if data_y[i] != -1:\n",
        "        y.append(1)\n",
        "    else:\n",
        "        y.append(-1)\n",
        "\n",
        "for i in data_x:\n",
        "  X.append(np.nan_to_num(i.flatten()))\n",
        "\n",
        "\n",
        "\n",
        "X_normalized = sklearn.preprocessing.normalize(X, norm='l2')\n",
        "\n",
        "X_pca = compute_pca(X_normalized)\n",
        "#X_pca = X_normalized\n",
        "\n",
        "all_data, all_label = shuffle(X_pca, y)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(12401, 350)\n",
            "(12401,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu5ERNZvk5CF",
        "outputId": "3a57ce42-7b9e-4d96-8507-f7c389fada69"
      },
      "source": [
        "cross_val(all_data, all_label, 1240)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch: 0\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.016935483870967744\n",
            "\n",
            "batch: 1\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.016129032258064516\n",
            "\n",
            "batch: 2\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.018548387096774192\n",
            "\n",
            "batch: 3\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.013709677419354839\n",
            "\n",
            "batch: 4\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.007258064516129033\n",
            "\n",
            "batch: 5\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.00967741935483871\n",
            "\n",
            "batch: 6\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.010483870967741936\n",
            "\n",
            "batch: 7\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.013709677419354839\n",
            "\n",
            "batch: 8\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.008870967741935484\n",
            "\n",
            "Error rate of each iteration: [0.016935483870967744, 0.016129032258064516, 0.018548387096774192, 0.013709677419354839, 0.007258064516129033, 0.00967741935483871, 0.010483870967741936, 0.013709677419354839, 0.008870967741935484]\n",
            "Average error rate:0.012813620071684587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpK3GoIovIKe"
      },
      "source": [
        "def cross_val_rbf(X, y, batch_size):\n",
        "    error_arr = []\n",
        "    subset_num = int(len(X)/batch_size)-1\n",
        "    for i in range(subset_num):\n",
        "        print(\"batch: \" + str(i))\n",
        "        error = 0\n",
        "        X_test = X[i*batch_size: (i+1)*batch_size]\n",
        "        y_test = y[i*batch_size: (i+1)*batch_size]\n",
        "        X_train = np.concatenate((X[0: i*batch_size], X[(i+1)*batch_size: len(X)]))\n",
        "        y_train = np.concatenate((y[0: i*batch_size], y[(i+1)*batch_size: len(y)]))\n",
        "\n",
        "        print('running svm')\n",
        "        cf = svm(kernel=\"rbf\")\n",
        "        cf.fit(X_train, y_train)\n",
        "\n",
        "        print('predicting')\n",
        "        result = cf.predict((X_test))\n",
        "        for j in range(len(result)):\n",
        "            if result[j] != y_test[j]:\n",
        "                error = error + 1\n",
        "        error_rate = error/batch_size\n",
        "        error_arr.append(error_rate)\n",
        "\n",
        "        print(\"error rate is \" + str(error_rate))\n",
        "        print()\n",
        "    \n",
        "    print (\"Error rate of each iteration: \" + str(error_arr))\n",
        "    print (\"Average error rate:\" + str(np.average(error_arr)))\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LU_AKuiUvVt6",
        "outputId": "a1bbfd2c-5caf-4244-b09e-4d632b1f3b8b"
      },
      "source": [
        "cross_val_rbf(all_data, all_label, 1240)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch: 0\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.016935483870967744\n",
            "\n",
            "batch: 1\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.016129032258064516\n",
            "\n",
            "batch: 2\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.018548387096774192\n",
            "\n",
            "batch: 3\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.013709677419354839\n",
            "\n",
            "batch: 4\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.007258064516129033\n",
            "\n",
            "batch: 5\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.00967741935483871\n",
            "\n",
            "batch: 6\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.010483870967741936\n",
            "\n",
            "batch: 7\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.013709677419354839\n",
            "\n",
            "batch: 8\n",
            "running svm\n",
            "predicting\n",
            "error rate is 0.008870967741935484\n",
            "\n",
            "Error rate of each iteration: [0.016935483870967744, 0.016129032258064516, 0.018548387096774192, 0.013709677419354839, 0.007258064516129033, 0.00967741935483871, 0.010483870967741936, 0.013709677419354839, 0.008870967741935484]\n",
            "Average error rate:0.012813620071684587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_73ggjCTo3sq",
        "outputId": "768c6d42-daeb-4948-95b6-abb36f6c0bfb"
      },
      "source": [
        "data = np.load(\"eeg_data.npz\")\n",
        "X = data['x']\n",
        "y = data['y']\n",
        "print(y.shape)\n",
        "ds = []\n",
        "for i in X:\n",
        "    ds.append(np.nan_to_num(i.flatten()))\n",
        "\n",
        "print(np.array(ds).shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12401,)\n",
            "(12401, 350)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd4OxrT-Z7MU"
      },
      "source": [
        "# 新段落"
      ]
    }
  ]
}